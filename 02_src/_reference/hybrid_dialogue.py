"""Hybrid dialogue orchestrator with Function Calling: Gemini batches + ask_qwen tool for numeric/ID fields."""

from __future__ import annotations

import base64
import copy
import json
from dataclasses import dataclass
from io import BytesIO
from pathlib import Path
from typing import Dict, List, Optional, Tuple

from PIL import Image, ImageDraw, ImageFont

from common import pdf_utils
from common.gemini_client import GeminiRestClient
from worker_job.constants import ALL_HEADERS
from worker_job.field_processors.base import (
    FIELD_STATUS_ERROR,
    FIELD_STATUS_NO_DATA,
    FIELD_STATUS_OK,
    FIELD_STATUS_SKIPPED,
    FieldResult,
    ProcessingContext,
)
from worker_job.tools import (
    ask_qwen,
    tool_result_to_field_result,
)
from worker_job.tools_definitions import get_tools_definition


# Numeric/ID fields that require ask_qwen tool (–û–ì–†–ù, –û–†–ù–ó, –Ω–æ–º–µ—Ä–∞ –∞—Ç—Ç–µ—Å—Ç–∞—Ç–æ–≤)
NUMERIC_FIELDS = {
    "field_07",   # –û–ì–†–ù –∞—É–¥–∏—Ä—É–µ–º–æ–≥–æ –ª–∏—Ü–∞
    "field_14",   # –û–ì–†–ù –∞—É–¥–∏—Ç–æ—Ä—Å–∫–æ–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏
    "field_15",   # –û–†–ù–ó –∞—É–¥–∏—Ç–æ—Ä—Å–∫–æ–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏
    "field_18",   # –û–†–ù–ó —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è –∞—É–¥–∏—Ç–∞
    "field_19",   # –ù–æ–º–µ—Ä –∞—Ç—Ç–µ—Å—Ç–∞—Ç–∞ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è
    "field_21",   # –û–†–ù–ó –≤—Ç–æ—Ä–æ–≥–æ –ª–∏—Ü–∞
    "field_22",   # –ù–æ–º–µ—Ä –∞—Ç—Ç–µ—Å—Ç–∞—Ç–∞ –≤—Ç–æ—Ä–æ–≥–æ –ª–∏—Ü–∞
}

# Optional numeric fields - –º–æ–≥—É—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ
# Gemini –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å no_data –ë–ï–ó –≤—ã–∑–æ–≤–∞ ask_qwen
OPTIONAL_NUMERIC_FIELDS = {
    "field_19",   # –ù–æ–º–µ—Ä –∞—Ç—Ç–µ—Å—Ç–∞—Ç–∞ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è (–º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å)
    "field_22",   # –ù–æ–º–µ—Ä –∞—Ç—Ç–µ—Å—Ç–∞—Ç–∞ –≤—Ç–æ—Ä–æ–≥–æ –ª–∏—Ü–∞ (–º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å)
}

# Extraction groups by document semantic blocks
EXTRACTION_GROUPS = [
    {
        "name": "audited_entity",
        "display_name": "–ê—É–¥–∏—Ä—É–µ–º–æ–µ –ª–∏—Ü–æ",
        "description": (
            "–î–∞–Ω–Ω—ã–µ –æ–± –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏, –≤ –æ—Ç–Ω–æ—à–µ–Ω–∏–∏ –∫–æ—Ç–æ—Ä–æ–π —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–æ –∞—É–¥–∏—Ç–æ—Ä—Å–∫–æ–µ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ. "
            "–≠—Ç–æ –∫–æ–º–ø–∞–Ω–∏—è, —á—å—è –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å –ø—Ä–æ–≤–µ—Ä—è–ª–∞—Å—å –∞—É–¥–∏—Ç–æ—Ä–∞–º–∏."
        ),
        "where_to_find": (
            "–°–≤–µ–¥–µ–Ω–∏—è –æ–± –∞—É–¥–∏—Ä—É–µ–º–æ–º –ª–∏—Ü–µ –º–æ–≥—É—Ç –±—ã—Ç—å —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω—ã –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–µ—Å—Ç–∞—Ö:\n"
            "- –¢–∏—Ç—É–ª—å–Ω—ã–π –ª–∏—Å—Ç –∑–∞–∫–ª—é—á–µ–Ω–∏—è\n"
            "- –ù–∞—á–∞–ª—å–Ω—ã–µ –∞–±–∑–∞—Ü—ã –∞—É–¥–∏—Ç–æ—Ä—Å–∫–æ–≥–æ –∑–∞–∫–ª—é—á–µ–Ω–∏—è\n"
            "- –ó–∞–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–∞—è —á–∞—Å—Ç—å –∑–∞–∫–ª—é—á–µ–Ω–∏—è ‚Äî –±–ª–æ–∫ —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º ¬´–ê—É–¥–∏—Ä—É–µ–º–æ–µ –ª–∏—Ü–æ¬ª "
            "–∏–ª–∏ ¬´–°–≤–µ–¥–µ–Ω–∏—è –æ–± –∞—É–¥–∏—Ä—É–µ–º–æ–º –ª–∏—Ü–µ¬ª"
        ),
        "fields": ["field_03", "field_04", "field_07"],
        "field_details": {
            "field_03": "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ ‚Äî –ø–æ–ª–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∞—É–¥–∏—Ä—É–µ–º–æ–≥–æ –ª–∏—Ü–∞",
            "field_04": "–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω–æ-–ø—Ä–∞–≤–æ–≤–∞—è —Ñ–æ—Ä–º–∞ (–û–ü–§) ‚Äî –ü–ê–û, –ê–û, –û–û–û, –ó–ê–û, –ú–ö–ü–ê–û –∏ —Ç.–¥.",
            "field_07": "–û–ì–†–ù ‚Äî –æ—Å–Ω–æ–≤–Ω–æ–π –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–π —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π –Ω–æ–º–µ—Ä (13 —Ü–∏—Ñ—Ä). "
                        "–ú–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –≤ –∑–∞–∫–ª—é—á–µ–Ω–∏–∏ ‚Äî —Ç–æ–≥–¥–∞ no_data.",
        },
        "block_discovery": True,  # –¢—Ä–µ–±—É–µ—Ç —Ñ–∞–∑—ã Block Discovery
    },
    {
        "name": "auditors",
        "display_name": "–ê—É–¥–∏—Ç–æ—Ä—ã",
        "description": (
            "–î–∞–Ω–Ω—ã–µ –æ–± –∞—É–¥–∏—Ç–æ—Ä—Å–∫–æ–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∏ –∞—É–¥–∏—Ç–æ—Ä–∞—Ö, —Ñ–æ—Ä–º–∏—Ä—É—é—â–∏—Ö –∑–∞–∫–ª—é—á–µ–Ω–∏–µ. "
            "–í–∫–ª—é—á–∞–µ—Ç —Ç—Ä–∏ –æ–±—ä–µ–∫—Ç–∞:\n"
            "1. –ê—É–¥–∏—Ç–æ—Ä—Å–∫–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è ‚Äî —é—Ä–ª–∏—Ü–æ, –ø—Ä–æ–≤–æ–¥–∏–≤—à–µ–µ –∞—É–¥–∏—Ç\n"
            "2. –†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∑–∞–¥–∞–Ω–∏—è –ø–æ –∞—É–¥–∏—Ç—É ‚Äî –ª–∏—Ü–æ, —è–≤–Ω–æ –æ–±–æ–∑–Ω–∞—á–µ–Ω–Ω–æ–µ –∫–∞–∫ "
            "¬´–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∞—É–¥–∏—Ç–∞¬ª –∏–ª–∏ ¬´–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∑–∞–¥–∞–Ω–∏—è –ø–æ –∞—É–¥–∏—Ç—É¬ª "
            "(–º–æ–∂–µ—Ç –±—ã—Ç—å —É–∫–∞–∑–∞–Ω–æ –≤ —Ç–µ–∫—Å—Ç–µ –∑–∞–∫–ª—é—á–µ–Ω–∏—è –∏–ª–∏ –≤ –±–ª–æ–∫–µ –ø–æ–¥–ø–∏—Å–µ–π). "
            "–ï—Å–ª–∏ —è–≤–Ω—ã—Ö —É–∫–∞–∑–∞–Ω–∏–π –Ω–µ—Ç ‚Äî –ø–µ—Ä–≤—ã–π –ø–æ–¥–ø–∏—Å–∞–Ω—Ç.\n"
            "3. –í—Ç–æ—Ä–æ–µ –ª–∏—Ü–æ, –ø–æ–¥–ø–∏—Å—ã–≤–∞—é—â–µ–µ –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å ‚Äî –¥—Ä—É–≥–æ–π –ø–æ–¥–ø–∏—Å–∞–Ω—Ç "
            "(–Ω–µ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∑–∞–¥–∞–Ω–∏—è –ø–æ –∞—É–¥–∏—Ç—É). –ú–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å."
        ),
        "where_to_find": (
            "–ö–∞–∫ –ø—Ä–∞–≤–∏–ª–æ (–Ω–æ –Ω–µ –≤—Å–µ–≥–¥–∞), –≤ –∑–∞–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ–π —á–∞—Å—Ç–∏ –∑–∞–∫–ª—é—á–µ–Ω–∏—è –µ—Å—Ç—å –±–ª–æ–∫ "
            "¬´–ê—É–¥–∏—Ç–æ—Ä¬ª –∏–ª–∏ ¬´–ê—É–¥–∏—Ç–æ—Ä—Å–∫–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è¬ª –∏–ª–∏ —á—Ç–æ-—Ç–æ –±–ª–∏–∑–∫–æ–µ. "
            "–¢–∞–∫–∂–µ —Å–≤–µ–¥–µ–Ω–∏—è –±–µ—Ä—É—Ç—Å—è –∏–∑ –±–ª–æ–∫–∞ –ø–æ–¥–ø–∏—Å–µ–π –∞—É–¥–∏—Ç–æ—Ä–æ–≤ –ø–æ–¥ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ–º."
        ),
        "fields": ["field_13", "field_14", "field_15", "field_17", "field_18", "field_19",
                   "field_20", "field_21", "field_22"],
        "field_details": {
            "field_13": "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∞—É–¥–∏—Ç–æ—Ä—Å–∫–æ–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏",
            "field_14": "–û–ì–†–ù –∞—É–¥–∏—Ç–æ—Ä—Å–∫–æ–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ (13 —Ü–∏—Ñ—Ä)",
            "field_15": "–û–†–ù–ó –∞—É–¥–∏—Ç–æ—Ä—Å–∫–æ–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ ‚Äî –ù–ï –ø—É—Ç–∞—Ç—å —Å –û–†–ù–ó –∞—É–¥–∏—Ç–æ—Ä–æ–≤! "
                        "–£ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ —Å–≤–æ–π –æ—Ç–¥–µ–ª—å–Ω—ã–π –û–†–ù–ó.",
            "field_17": "–§–ò–û —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è –∑–∞–¥–∞–Ω–∏—è –ø–æ –∞—É–¥–∏—Ç—É",
            "field_18": "–û–†–ù–ó —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è –∑–∞–¥–∞–Ω–∏—è –ø–æ –∞—É–¥–∏—Ç—É ‚Äî –Ω–æ–º–µ—Ä –≤ —Ä–µ–µ—Å—Ç—Ä–µ –∞—É–¥–∏—Ç–æ—Ä–æ–≤",
            "field_19": "–ù–æ–º–µ—Ä –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –∞—Ç—Ç–µ—Å—Ç–∞—Ç–∞ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è (–µ—Å–ª–∏ –∏–º–µ–µ—Ç—Å—è)",
            "field_20": "–§–ò–û –≤—Ç–æ—Ä–æ–≥–æ –ª–∏—Ü–∞, –ø–æ–¥–ø–∏—Å—ã–≤–∞—é—â–µ–≥–æ –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å",
            "field_21": "–û–†–ù–ó –≤—Ç–æ—Ä–æ–≥–æ –ª–∏—Ü–∞",
            "field_22": "–ù–æ–º–µ—Ä –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –∞—Ç—Ç–µ—Å—Ç–∞—Ç–∞ –≤—Ç–æ—Ä–æ–≥–æ –ª–∏—Ü–∞ (–µ—Å–ª–∏ –∏–º–µ–µ—Ç—Å—è)",
        },
        "special_notes": (
            "–í–ê–ñ–ù–û: –î–∞–Ω–Ω—ã–µ –æ–± –∞—É–¥–∏—Ç–æ—Ä—Å–∫–æ–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∏ –∞—É–¥–∏—Ç–æ—Ä–∞—Ö —á–∞—Å—Ç–æ –ø–µ—Ä–µ–ø–ª–µ—Ç–µ–Ω—ã –≤ –æ–¥–Ω–æ–º –±–ª–æ–∫–µ!\n\n"
            "üîç –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –†–£–ö–û–í–û–î–ò–¢–ï–õ–Ø –ó–ê–î–ê–ù–ò–Ø –ü–û –ê–£–î–ò–¢–£ (field_17-19):\n\n"
            "–ü–†–ò–û–†–ò–¢–ï–¢ 1 ‚Äî –Ø–≤–Ω–æ–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —É–∫–∞–∑–∞–Ω–∏–µ (–í–°–ï–ì–î–ê –ü–†–û–í–ï–†–Ø–ô –°–ù–ê–ß–ê–õ–ê!):\n"
            "- –ò—â–∏ —Ñ—Ä–∞–∑—ã: ¬´–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∞—É–¥–∏—Ç–∞¬ª, ¬´–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∑–∞–¥–∞–Ω–∏—è –ø–æ –∞—É–¥–∏—Ç—É¬ª, "
            "¬´—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∞—É–¥–∏—Ç–∞, –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –∫–æ—Ç–æ—Ä–æ–≥–æ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–æ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ¬ª, "
            "¬´–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∑–∞–¥–∞–Ω–∏—è¬ª, –∏–ª–∏ —Å—Ö–æ–∂–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã\n"
            "- –£–∫–∞–∑–∞–Ω–∏–µ –º–æ–∂–µ—Ç –±—ã—Ç—å:\n"
            "  * –í –±–ª–æ–∫–µ –ø–æ–¥–ø–∏—Å–µ–π (—Ä—è–¥–æ–º —Å –ø–æ–¥–ø–∏—Å—å—é –∏–ª–∏ –§–ò–û)\n"
            "  * –í —Ç–µ–∫—Å—Ç–µ –∑–∞–∫–ª—é—á–µ–Ω–∏—è (–¥–æ –±–ª–æ–∫–∞ –ø–æ–¥–ø–∏—Å–µ–π)\n"
            "- –õ–∏—Ü–æ —Å –¢–ê–ö–ò–ú —É–∫–∞–∑–∞–Ω–∏–µ–º = field_17 (—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∑–∞–¥–∞–Ω–∏—è)\n"
            "- –î—Ä—É–≥–æ–π –ø–æ–¥–ø–∏—Å–∞–Ω—Ç (–µ—Å–ª–∏ –µ—Å—Ç—å) = field_20 (–≤—Ç–æ—Ä–æ–µ –ª–∏—Ü–æ)\n\n"
            "‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ù–û: ¬´–î–∏—Ä–µ–∫—Ç–æ—Ä –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏¬ª / ¬´–ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä¬ª ‚â† ¬´–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∑–∞–¥–∞–Ω–∏—è –ø–æ –∞—É–¥–∏—Ç—É¬ª!\n"
            "–ü—Ä–∏–º–µ—Ä:\n"
            "  –ü–æ–¥–ø–∏—Å—å 1: –ò–≤–∞–Ω–æ–≤ –ò.–ò. ‚Äî –ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä –ê–û ¬´–ê—É–¥–∏—Ç¬ª\n"
            "  –ü–æ–¥–ø–∏—Å—å 2: –ü–µ—Ç—Ä–æ–≤ –ü.–ü. ‚Äî –†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∞—É–¥–∏—Ç–∞\n"
            "  ‚Üí field_17 = –ü–µ—Ç—Ä–æ–≤ –ü.–ü. (—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –ó–ê–î–ê–ù–ò–Ø, –¥–∞–∂–µ –µ—Å–ª–∏ –≤—Ç–æ—Ä–æ–π –ø–æ –ø–æ—Ä—è–¥–∫—É)\n"
            "  ‚Üí field_20 = –ò–≤–∞–Ω–æ–≤ –ò.–ò. (–¥–∏—Ä–µ–∫—Ç–æ—Ä –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏, –ù–ï —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∑–∞–¥–∞–Ω–∏—è)\n\n"
            "–ü–†–ò–û–†–ò–¢–ï–¢ 2 ‚Äî –ü–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ–µ –ø—Ä–∞–≤–∏–ª–æ (–¢–û–õ–¨–ö–û –µ—Å–ª–∏ –Ω–µ—Ç —è–≤–Ω—ã—Ö —É–∫–∞–∑–∞–Ω–∏–π!):\n"
            "- –ï—Å–ª–∏ –ù–ò –¥–ª—è –∫–æ–≥–æ –ù–ï —É–∫–∞–∑–∞–Ω–æ ¬´–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∞—É–¥–∏—Ç–∞¬ª –∏–ª–∏ —Å—Ö–æ–∂–µ–µ\n"
            "- –¢–æ–≥–¥–∞ –ø–µ—Ä–≤—ã–π –ø–æ–¥–ø–∏—Å–∞–Ω—Ç = field_17\n"
            "- –í—Ç–æ—Ä–æ–π –ø–æ–¥–ø–∏—Å–∞–Ω—Ç (–µ—Å–ª–∏ –µ—Å—Ç—å) = field_20\n\n"
            "–ü—Ä–∏–º–µ—Ä —Å —è–≤–Ω—ã–º —É–∫–∞–∑–∞–Ω–∏–µ–º:\n"
            "¬´–§–æ–º–∏–Ω –ê.–ë., –ª–∏—Ü–æ, —É–ø–æ–ª–Ω–æ–º–æ—á–µ–Ω–Ω–æ–µ... –Ω–∞ –ø–æ–¥–ø–∏—Å–∞–Ω–∏–µ –æ—Ç –∏–º–µ–Ω–∏ "
            "–ê–û ¬´–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –î–æ–≤–µ—Ä–∏—è ‚Äì –ê—É–¥–∏—Ç¬ª (–û–†–ù–ó ‚Äì 12006020338), —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∞—É–¥–∏—Ç–∞ (–û–†–ù–ó ‚Äì 21906104343)¬ª\n"
            "–ó–¥–µ—Å—å:\n"
            "- 12006020338 ‚Äî –û–†–ù–ó –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ (–ø–æ—Å–ª–µ –Ω–∞–∑–≤–∞–Ω–∏—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏)\n"
            "- 21906104343 ‚Äî –û–†–ù–ó —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è –∞—É–¥–∏—Ç–∞ (–§–æ–º–∏–Ω –ê.–ë. = field_17)\n"
            "- –§—Ä–∞–∑–∞ ¬´—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∞—É–¥–∏—Ç–∞¬ª ‚Äî –Ø–í–ù–û–ï —É–∫–∞–∑–∞–Ω–∏–µ\n\n"
            "–í—Ç–æ—Ä–æ–µ –ª–∏—Ü–æ –º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å ‚Äî —Ç–æ–≥–¥–∞ field_20, field_21, field_22 ‚Üí no_data."
        ),
        "block_discovery": True,  # –¢—Ä–µ–±—É–µ—Ç —Ñ–∞–∑—ã Block Discovery
    },
    {
        "name": "metadata",
        "display_name": "–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞",
        "description": "–í–∏–¥ –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏ –∏ –¥–∞—Ç–∞ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∑–∞–∫–ª—é—á–µ–Ω–∏—è",
        "where_to_find": (
            "- –í–∏–¥ –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏: —Ç–∏—Ç—É–ª—å–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞, –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∑–∞–∫–ª—é—á–µ–Ω–∏—è, –ø–µ—Ä–≤—ã–π –ø–∞—Ä–∞–≥—Ä–∞—Ñ. "
            "–í–∞—Ä–∏–∞–Ω—Ç—ã: –≥–æ–¥–æ–≤–∞—è/–ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–∞—è –±—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫–∞—è (—Ñ–∏–Ω–∞–Ω—Å–æ–≤–∞—è) –æ—Ç—á—ë—Ç–Ω–æ—Å—Ç—å, "
            "–∫–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤–∞—è –æ—Ç—á—ë—Ç–Ω–æ—Å—Ç—å, –µ–¥–∏–Ω–∞—è (–û–°–ë–£ –∏ –ú–°–§–û), —Ä–∞—Å–∫—Ä—ã–≤–∞–µ–º–∞—è –∏ –¥—Ä.\n"
            "- –î–∞—Ç–∞ –∑–∞–∫–ª—é—á–µ–Ω–∏—è: –∫–æ–Ω–µ—Ü –∑–∞–∫–ª—é—á–µ–Ω–∏—è, –±–ª–æ–∫ –ø–æ–¥–ø–∏—Å–µ–π. "
            "–≠—Ç–æ –¥–∞—Ç–∞, –∫–æ–≥–¥–∞ –∞—É–¥–∏—Ç–æ—Ä –∑–∞–≤–µ—Ä—à–∏–ª –ø—Ä–æ–≤–µ—Ä–∫—É. –î–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø–æ—Å–ª–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è –æ—Ç—á–µ—Ç–Ω–æ–≥–æ –≥–æ–¥–∞."
        ),
        "fields": ["field_10", "field_23"],
        "field_details": {
            "field_10": "–í–∏–¥ –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏ ‚Äî –≥–æ–¥–æ–≤–∞—è/–ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–∞—è, –±—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫–∞—è/–∫–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω–∞—è/—Ñ–∏–Ω–∞–Ω—Å–æ–≤–∞—è, "
                        "—Ä–∞—Å–∫—Ä—ã–≤–∞–µ–º–∞—è. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—Å—è –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å ‚Äî –≥–æ–¥–æ–≤–∞—è.",
            "field_23": "–î–∞—Ç–∞ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∞—É–¥–∏—Ç–æ—Ä—Å–∫–æ–≥–æ –∑–∞–∫–ª—é—á–µ–Ω–∏—è ‚Äî –æ–±—ã—á–Ω–æ —Ñ–µ–≤—Ä–∞–ª—å-–º–∞—Ä—Ç —Å–ª–µ–¥—É—é—â–µ–≥–æ –≥–æ–¥–∞",
        },
        "block_discovery": False,  # –ü—Ä–æ—Å—Ç—ã–µ –ø–æ–ª—è, –Ω–µ —Ç—Ä–µ–±—É—é—Ç Block Discovery
    },
    {
        "name": "comments",
        "display_name": "–ó–∞–º–µ—á–∞–Ω–∏—è",
        "description": "–°–≤–æ–±–æ–¥–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –ø–æ –∑–∞–∫–ª—é—á–µ–Ω–∏—é, –≤—ã—è–≤–ª–µ–Ω–Ω—ã–µ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ",
        "where_to_find": "‚Äî",
        "fields": ["field_31"],
        "field_details": {
            "field_31": "–°–≤–æ–±–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç ‚Äî –∑–∞–º–µ—á–∞–Ω–∏—è, –Ω–∞–ø—Ä–∏–º–µ—Ä: ¬´–Ω–µ —É–∫–∞–∑–∞–ª–∏ –ø–æ–¥–ø–∏—Å—ã–≤–∞—é—â–µ–≥–æ –∞—É–¥–∏—Ç–æ—Ä–∞¬ª, "
                        "¬´–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤—Ç–æ—Ä–æ–µ –ª–∏—Ü–æ¬ª –∏ —Ç.–ø.",
        },
        "block_discovery": False,
    },
]


class HybridDialogueManager:
    def __init__(
        self,
        gemini_client: Optional[GeminiRestClient] = None,
        qwen_client=None,
        run_logger=None,
        log_dir: Optional[Path] = None,
    ):
        self.client = gemini_client or GeminiRestClient()
        self.qwen_client = qwen_client
        self.run_logger = run_logger
        self.log_dir = log_dir
        self.messages: List[Dict] = []  # Conversation history as messages array
        self.tools = get_tools_definition()
        self.pages_cache: Dict[int, bytes] = {}  # Golden source: {global_index: marked_image_bytes}
    
    def set_log_dir(self, log_dir: Path):
        """Set log directory for saving qwen images."""
        self.log_dir = log_dir

    def _log(self, message: str):
        if self.run_logger:
            self.run_logger(message)

    @staticmethod
    def _field_name(field_id: str) -> str:
        try:
            idx = int(field_id.split("_")[1])
            return ALL_HEADERS[idx]
        except Exception:
            return field_id
    
    @staticmethod
    def _add_marker_to_image(image_bytes: bytes, global_index: int) -> bytes:
        """
        Add visual marker [G{global_index}] to top-left corner of image.
        Marker is on white background for contrast with any document content.
        """
        img = Image.open(BytesIO(image_bytes))
        draw = ImageDraw.Draw(img)
        
        marker_text = f"[G{global_index}]"
        
        # Try to use arial, fallback to default
        try:
            font = ImageFont.truetype("arial.ttf", 24)
        except Exception:  # noqa: BLE001
            try:
                font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", 24)
            except Exception:  # noqa: BLE001
                font = ImageFont.load_default()
        
        # Calculate text size
        bbox = draw.textbbox((0, 0), marker_text, font=font)
        text_width = bbox[2] - bbox[0]
        text_height = bbox[3] - bbox[1]
        
        # Position: top-left with 6px offset
        x, y = 6, 6
        padding = 4
        
        # Draw white background rectangle
        draw.rectangle(
            [x - padding, y - padding, x + text_width + padding, y + text_height + padding],
            fill="white",
            outline="black",
            width=1
        )
        
        # Draw text
        draw.text((x, y), marker_text, fill="black", font=font)
        
        # Save to bytes
        output = BytesIO()
        img.save(output, format="JPEG", quality=85)
        return output.getvalue()
    
    def _initialize_pages_cache(self, context: ProcessingContext) -> None:
        """
        Initialize golden source cache: render all pages from pages_union with markers.
        This cache is the ONLY source of images for both Gemini and Qwen.
        """
        pages_union = context.pages_union or []
        if not pages_union:
            self._log("pages_cache_init: no pages in union")
            return
        
        sorted_pages = sorted(pages_union, key=lambda p: getattr(p, "global_index", 0))
        indices = [getattr(p, "global_index", None) for p in sorted_pages]
        self._log(f"pages_cache_init: processing {len(sorted_pages)} pages, indices={indices}")
        
        for page in sorted_pages:
            global_idx = getattr(page, "global_index", None)
            if global_idx is None:
                continue
            
            if not getattr(page, "part", None) or not getattr(page.part, "local_path", None):
                self._log(f"pages_cache_init: skip page g{global_idx} (no part/path)")
                continue
            
            try:
                # Render page
                rendered = pdf_utils.render_pages_batch(
                    page.part.local_path, 
                    [page.source_page - 1], 
                    dpi=150, 
                    quality=85
                )
                if not rendered:
                    self._log(f"pages_cache_init: render failed for g{global_idx}")
                    continue
                
                raw_image = rendered[0][1]
                
                # Add marker
                marked_image = self._add_marker_to_image(raw_image, global_idx)
                
                # Cache
                self.pages_cache[global_idx] = marked_image
                self._log(f"pages_cache_ready: g{global_idx} size={len(marked_image)}b")
                
            except Exception as e:  # noqa: BLE001
                self._log(f"pages_cache_init: error for g{global_idx}: {e}")
        
        self._log(f"pages_cache_complete: {len(self.pages_cache)} pages cached")

    def _render_union_pages(self, context: ProcessingContext, max_pages: int = 8) -> Tuple[List[bytes], List[int]]:
        """
        Get images from cache for pages_union (up to max_pages).
        Returns: (list of marked images, list of global_indices)
        """
        pages_union = context.pages_union or []
        sorted_pages = sorted(pages_union, key=lambda p: getattr(p, "global_index", 0))[:max_pages]
        images: List[bytes] = []
        page_nums: List[int] = []
        
        for page in sorted_pages:
            global_idx = getattr(page, "global_index", None)
            if global_idx is None:
                continue
            
            # Get from cache
            if global_idx in self.pages_cache:
                images.append(self.pages_cache[global_idx])
                page_nums.append(global_idx)
            else:
                self._log(f"render_union_pages: g{global_idx} not in cache")
        
        return images, page_nums

    def _pick_page_num(self, context: ProcessingContext, prefer_tail: bool = False) -> Optional[int]:
        """Pick page number from pages_union (all available pages)."""
        union = context.pages_union or []
        if union:
            sorted_union = sorted(union, key=lambda p: getattr(p, "global_index", 0))
            return getattr(sorted_union[-1 if prefer_tail else 0], "global_index", None)
        return None

    def _render_single_page(self, context: ProcessingContext, target_page_num: Optional[int]) -> Optional[bytes]:
        """
        Get image from cache by global_index.
        Returns: marked image bytes or None
        """
        if target_page_num is None:
            return None
        
        # Get from cache
        if target_page_num in self.pages_cache:
            return self.pages_cache[target_page_num]
        else:
            self._log(f"render_single_page: g{target_page_num} not in cache")
            return None

    def _build_system_prompt(self) -> str:
        return (
            "–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∞—É–¥–∏—Ç–æ—Ä—Å–∫–∏—Ö –∑–∞–∫–ª—é—á–µ–Ω–∏–π.\n\n"
            "üî¢ –ù–£–ú–ï–†–ê–¶–ò–Ø –°–¢–†–ê–ù–ò–¶:\n"
            "–ö–∞–∂–¥–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–∞ –≤ –≤–µ—Ä—Ö–Ω–µ–º –ª–µ–≤–æ–º —É–≥–ª—É: [G1], [G2], [G3] –∏ —Ç.–¥.\n"
            "–≠—Ç–∏ –Ω–æ–º–µ—Ä–∞ ‚Äî —Ç–æ—á–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã —Å—Ç—Ä–∞–Ω–∏—Ü –≤ —Å–∏—Å—Ç–µ–º–µ (global_index).\n"
            "–ü—Ä–∏ –≤—ã–∑–æ–≤–µ tool ask_qwen –∏—Å–ø–æ–ª—å–∑—É–π –ß–ò–°–õ–û –ò–ó –ú–ê–†–ö–ò–†–û–í–ö–ò –∫–∞–∫ page_num.\n"
            "–ü—Ä–∏–º–µ—Ä: –≤–∏–¥–∏—à—å –º–∞—Ä–∫–µ—Ä [G5] ‚Üí –≤—ã–∑—ã–≤–∞–π ask_qwen —Å page_num=5.\n\n"
            "–û–ë–©–ò–ï –ü–†–ê–í–ò–õ–ê:\n"
            "1. –¢–µ–∫—Å—Ç–æ–≤—ã–µ –ø–æ–ª—è: –∏–∑–≤–ª–µ–∫–∞–π –Ω–∞–ø—Ä—è–º—É—é –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n"
            "2. –ß–∏—Å–ª–æ–≤—ã–µ/ID –ø–æ–ª—è (–û–ì–†–ù, –û–†–ù–ó, –Ω–æ–º–µ—Ä–∞ –∞—Ç—Ç–µ—Å—Ç–∞—Ç–æ–≤):\n"
            "   - –°–Ω–∞—á–∞–ª–∞ –û–¶–ï–ù–ò, –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ –Ω–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ö\n"
            "   - –ï–°–õ–ò –¥–∞–Ω–Ω—ã–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç ‚Üí –≤—ã–∑–æ–≤–∏ tool ask_qwen —Å –î–ï–¢–ê–õ–¨–ù–û–ô –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π\n"
            "   - –ï–°–õ–ò –¥–∞–Ω–Ω—ã—Ö —Ç–æ—á–Ω–æ –Ω–µ—Ç ‚Üí –≤–µ—Ä–Ω–∏ status='no_data' –ë–ï–ó –≤—ã–∑–æ–≤–∞ ask_qwen\n"
            "   - –ù–ï –ø–∏—à–∏ —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞–ø—Ä—è–º—É—é –≤ –æ—Ç–≤–µ—Ç–µ!\n\n"
            "–°–¢–ê–¢–£–°–´:\n"
            '- "ok": –¥–∞–Ω–Ω—ã–µ –Ω–∞–π–¥–µ–Ω—ã –∏ –∏–∑–≤–ª–µ—á–µ–Ω—ã\n'
            '- "no_data": –ø–æ–ª–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ (–Ω–µ –æ—à–∏–±–∫–∞!)\n'
            '- "error": –æ—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è\n\n'
            "–¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö question_text –¥–ª—è ask_qwen:\n"
            "- –û–ø–∏—à–∏ –±–ª–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞, –≥–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏–µ (–Ω–∞–∑–≤–∞–Ω–∏–µ –±–ª–æ–∫–∞, —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ)\n"
            "- –£–∫–∞–∂–∏ –æ–∫—Ä—É–∂–∞—é—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (–∫–∞–∫–æ–π —Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–¥/–ø–æ—Å–ª–µ –∏—Å–∫–æ–º–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è)\n"
            "- –î–ª—è –û–†–ù–ó/–∞—Ç—Ç–µ—Å—Ç–∞—Ç–æ–≤ —Ñ–∏–∑–ª–∏—Ü ‚Äî —É–∫–∞–∂–∏ –§–ò–û –ª–∏—Ü–∞, —á–µ–π –Ω–æ–º–µ—Ä –∏—â–µ–º\n"
            "- –î–ª—è –û–ì–†–ù/–û–†–ù–ó –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ ‚Äî —É–∫–∞–∂–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –±–ª–æ–∫–∞ –∏–ª–∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏\n"
            "- –ù–ï –≤–∫–ª—é—á–∞–π —Å–∞–º –∏—Å–∫–æ–º—ã–π –Ω–æ–º–µ—Ä –≤ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é!\n\n"
            "üîç –í–ê–õ–ò–î–ê–¶–ò–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–û–í ask_qwen:\n"
            "–ü–æ—Å–ª–µ –≤—ã–∑–æ–≤–∞ ask_qwen —Ç—ã –ø–æ–ª—É—á–∏—à—å –æ—Ç–≤–µ—Ç —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º success/no_data/error.\n\n"
            "‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ù–û: –î–ê–ñ–ï –ü–†–ò status='success' —Ç—ã –û–ë–Ø–ó–ê–ù –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ö–û–ù–¢–ï–ö–°–¢ –∏ –ü–û–Ø–°–ù–ï–ù–ò–ï!\n\n"
            "–í –æ—Ç–≤–µ—Ç–µ –±—É–¥—É—Ç –ø–æ–ª—è:\n"
            "- qwen_context ‚Äî —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Ç–µ–∫—Å—Ç–∞, –æ—Ç–∫—É–¥–∞ –∏–∑–≤–ª–µ—á–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ\n"
            "- qwen_explanation ‚Äî —á—Ç–æ –∏–º–µ–Ω–Ω–æ –Ω–∞—à—ë–ª Qwen\n\n"
            "–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ü–†–û–í–ï–†–¨:\n"
            "1. –ö–û–ù–¢–ï–ö–°–¢ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –ù–£–ñ–ù–´–ô –æ–±—ä–µ–∫—Ç?\n"
            "   –ü—Ä–∏–º–µ—Ä—ã –ù–ï–ü–†–ê–í–ò–õ–¨–ù–û–ì–û –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞:\n"
            "   - –ò—â–µ–º –û–†–ù–ó –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏, –∞ context='–ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä... –û–†–ù–ó 12345' ‚Üí —ç—Ç–æ –û–†–ù–ó —Ñ–∏–∑–ª–∏—Ü–∞!\n"
            "   - –ò—â–µ–º –û–ì–†–ù –æ–¥–Ω–æ–π –∫–æ–º–ø–∞–Ω–∏–∏, –∞ context —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –î–†–£–ì–û–ô –∫–æ–º–ø–∞–Ω–∏–∏ ‚Üí –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ!\n"
            "   - –ò—â–µ–º –û–†–ù–ó —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è –∞—É–¥–∏—Ç–∞, –∞ context='–≤—Ç–æ—Ä–æ–µ –ª–∏—Ü–æ' ‚Üí –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ!\n"
            "   - –ò—â–µ–º –û–†–ù–ó —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è –∞—É–¥–∏—Ç–∞, –∞ context='–î–∏—Ä–µ–∫—Ç–æ—Ä –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏' "
            "–ë–ï–ó —Å–ª–æ–≤ '—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∞—É–¥–∏—Ç–∞' ‚Üí –≤–æ–∑–º–æ–∂–Ω–æ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ! –ü—Ä–æ–≤–µ—Ä—å –≤–µ—Å—å —Ç–µ–∫—Å—Ç.\n\n"
            "2. –ü–û–Ø–°–ù–ï–ù–ò–ï –ª–æ–≥–∏—á–Ω–æ –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∑–∞–¥–∞—á–µ?\n"
            "   - –ï—Å–ª–∏ Qwen –ø–æ—è—Å–Ω–∏–ª, —á—Ç–æ –Ω–∞—à—ë–ª –Ω–µ —Ç–∞–º, –≥–¥–µ –¥–æ–ª–∂–µ–Ω –±—ã–ª ‚Üí –ü–û–í–¢–û–†–ò –∑–∞–ø—Ä–æ—Å\n\n"
            "–î–ï–ô–°–¢–í–ò–Ø –ü–†–ò –û–ë–ù–ê–†–£–ñ–ï–ù–ò–ò –û–®–ò–ë–ö–ò:\n"
            "- –ï–°–õ–ò –∫–æ–Ω—Ç–µ–∫—Å—Ç —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –î–†–£–ì–û–ô –æ–±—ä–µ–∫—Ç ‚Üí –ü–û–í–¢–û–†–ò ask_qwen —Å –£–¢–û–ß–ù–Å–ù–ù–û–ô –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π\n"
            "  * –Ø–≤–Ω–æ —É–∫–∞–∂–∏, –∫–∞–∫–æ–π –æ–±—ä–µ–∫—Ç –ù–ï –ù–£–ñ–ï–ù (–Ω–∞–ø—Ä–∏–º–µ—Ä: '–ù–ï –≥–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä')\n"
            "  * –£—Ç–æ—á–Ω–∏ –∫—Ä–∏—Ç–µ—Ä–∏–∏ –ø–æ–∏—Å–∫–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä: '–û–†–ù–ó –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏, –Ω–µ —Ñ–∏–∑–ª–∏—Ü–∞')\n"
            "  * –ú–æ–∂–µ—à—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç—É –∂–µ —Å—Ç—Ä–∞–Ω–∏—Ü—É, –Ω–æ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π\n"
            "- –ï–°–õ–ò –≤—Å—ë –ø—Ä–∞–≤–∏–ª—å–Ω–æ ‚Üí –ø–µ—Ä–µ—Ö–æ–¥–∏ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –ø–æ–ª—é\n\n"
            "–í–ê–ñ–ù–û:\n"
            "- –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏\n"
            "- –î–µ—Ç–∞–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø–µ –ø–æ–ª–µ–π –±—É–¥—É—Ç –≤ –∑–∞–ø—Ä–æ—Å–∞—Ö"
        )

    def _build_block_discovery_prompt(self, group: Dict, page_nums: List[int]) -> str:
        """Build prompt for Block Discovery phase."""
        return (
            f"# –§–ê–ó–ê 1: –ü–æ–∏—Å–∫ –±–ª–æ–∫–æ–≤ —Å –¥–∞–Ω–Ω—ã–º–∏\n\n"
            f"## –ì—Ä—É–ø–ø–∞ –¥–∞–Ω–Ω—ã—Ö: {group['display_name']}\n\n"
            f"**–û–ø–∏—Å–∞–Ω–∏–µ:**\n{group['description']}\n\n"
            f"**–ì–¥–µ –∏—Å–∫–∞—Ç—å:**\n{group['where_to_find']}\n\n"
            f"**–î–æ—Å—Ç—É–ø–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã:** {page_nums or '–Ω–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü'}\n\n"
            f"**–ó–∞–¥–∞—á–∞:**\n"
            f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–æ–∫—É–º–µ–Ω—Ç –∏ –Ω–∞–π–¥–∏ –±–ª–æ–∫–∏, –≥–¥–µ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ —ç—Ç–æ–π –≥—Ä—É–ø–ø—ã.\n\n"
            f"**–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ (JSON):**\n"
            "{\n"
            '  "blocks": [\n'
            '    {\n'
            '      "page_num": <–Ω–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã>,\n'
            '      "semantic_position": "<–æ–±—â–∞—è –æ–±–ª–∞—Å—Ç—å –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ: –≤–µ—Ä—Ö/—Ü–µ–Ω—Ç—Ä/–Ω–∏–∑>",\n'
            '      "description": "<–∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –±–ª–æ–∫–∞>"\n'
            '    }\n'
            '  ],\n'
            '  "notes": "<–ª—é–±—ã–µ –∑–∞–º–µ—á–∞–Ω–∏—è –æ –ø–æ–∏—Å–∫–µ>"\n'
            "}"
        )

    def _build_field_extraction_prompt(self, group: Dict, page_nums: List[int], blocks_info: Optional[str] = None) -> str:
        """Build prompt for Field Extraction phase."""
        # Build field instructions with detailed requirements
        fields_list = []
        for fid in group["fields"]:
            fname = self._field_name(fid)
            field_desc = group["field_details"].get(fid, fname)

            if fid in NUMERIC_FIELDS:
                # Numeric field with detailed ask_qwen requirements
                is_optional = fid in OPTIONAL_NUMERIC_FIELDS

                optional_note = ""
                if is_optional:
                    optional_note = (
                        f"\n  ‚ö†Ô∏è –í–ê–ñ–ù–û: –≠—Ç–æ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –ø–æ–ª–µ!\n"
                        f"  - –°–Ω–∞—á–∞–ª–∞ –û–¶–ï–ù–ò: –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ö\n"
                        f"  - –ï–°–õ–ò –∑–Ω–∞—á–µ–Ω–∏—è —Ç–æ—á–Ω–æ –ù–ï–¢ ‚Üí –≤–µ—Ä–Ω–∏ status='no_data', reasoning=['not_found_in_document'] "
                        f"–ë–ï–ó –≤—ã–∑–æ–≤–∞ ask_qwen\n"
                        f"  - –ï–°–õ–ò –∑–Ω–∞—á–µ–Ω–∏–µ –ï–°–¢–¨ ‚Üí –≤—ã–∑–æ–≤–∏ ask_qwen —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π\n"
                    )

                fields_list.append(
                    f"**{fid} ({fname})**\n"
                    f"  - –û–ø–∏—Å–∞–Ω–∏–µ: {field_desc}\n"
                    f"  - –¢–∏–ø: —á–∏—Å–ª–æ–≤–æ–µ/ID –ø–æ–ª–µ{' (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ)' if is_optional else ''}\n"
                    f"{optional_note}"
                    f"  - –î–µ–π—Å—Ç–≤–∏–µ: {'–ï–°–õ–ò –¥–∞–Ω–Ω—ã–µ –µ—Å—Ç—å ‚Üí ' if is_optional else ''}–≤—ã–∑–æ–≤–∏ tool ask_qwen —Å –î–ï–¢–ê–õ–¨–ù–û–ô –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π:\n"
                    f"    * field_id: \"{fid}\"\n"
                    f"    * page_num: –Ω–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã, –≥–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏–µ\n"
                    f"    * question_text: –î–ï–¢–ê–õ–¨–ù–ê–Ø –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è\n\n"
                    f"  –¢–†–ï–ë–û–í–ê–ù–ò–Ø –∫ question_text:\n"
                    f"  - –û–ø–∏—à–∏ –±–ª–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–Ω–∞–∑–≤–∞–Ω–∏–µ, —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ)\n"
                    f"  - –£–∫–∞–∂–∏ –æ–∫—Ä—É–∂–∞—é—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (—Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–¥/–ø–æ—Å–ª–µ)\n"
                    f"  - –î–ª—è –û–†–ù–ó/–∞—Ç—Ç–µ—Å—Ç–∞—Ç–æ–≤ —Ñ–∏–∑–ª–∏—Ü: —É–∫–∞–∂–∏ –§–ò–û –ª–∏—Ü–∞\n"
                    f"  - –ù–ï –≤–∫–ª—é—á–∞–π —Å–∞–º –∏—Å–∫–æ–º—ã–π –Ω–æ–º–µ—Ä!\n\n"
                    f"  üî¥ –ü—Ä–∏ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø–æ—Ö–æ–∂–∏—Ö –æ–±—ä–µ–∫—Ç–∞—Ö (–Ω–µ—Å–∫–æ–ª—å–∫–æ –û–†–ù–ó/–û–ì–†–ù):\n"
                    f"  - –°–º–æ—Ç—Ä–∏ –Ω–∞ –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ï —Å—Ç—Ä–∞–Ω–∏—Ü—ã, –æ–ø—Ä–µ–¥–µ–ª–∏ —Ñ–∏–∑–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ\n"
                    f"  - –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π semantic_position –∏–∑ Block Discovery –¥–ª—è –ø–æ–∑–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è\n"
                    f"  - –û–ø–∏—à–∏ –¥–ª—è —á–µ–ª–æ–≤–µ–∫–∞, —Å–º–æ—Ç—Ä—è—â–µ–≥–æ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É: –≥–¥–µ –Ω–µ –Ω—É–∂–Ω—ã–µ, –≥–¥–µ –Ω—É–∂–Ω—ã–π, –∫–∞–∫ —Ä–∞–∑–ª–∏—á–∏—Ç—å\n"
                    f"  - –î–∞–π –ø–æ—à–∞–≥–æ–≤—ã–µ –¥–µ–π—Å—Ç–≤–∏—è\n\n"
                    f"  –ü—Ä–∏–º–µ—Ä (–º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –û–†–ù–ó):\n"
                    f'  "–ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ 3 –û–†–ù–ó. –ù—É–∂–µ–Ω –û–†–ù–ó –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∏–∑ –±–ª–æ–∫–∞ ¬´–ê—É–¥–∏—Ç–æ—Ä—Å–∫–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è¬ª '
                    f'–≤ —Å–∞–º–æ–º –Ω–∏–∑—É —Å–ª–µ–≤–∞. –ù–ï –ø—É—Ç–∞—Ç—å —Å –û–†–ù–ó —Ñ–∏–∑–ª–∏—Ü –≤ –±–ª–æ–∫–µ ¬´–ü–æ–¥–ø–∏—Å–∏¬ª –≤ —Ü–µ–Ω—Ç—Ä–µ. '
                    f'–®–∞–≥–∏: 1) –ù–∞–π–¥–∏ ¬´–ê—É–¥–∏—Ç–æ—Ä—Å–∫–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è¬ª –≤–Ω–∏–∑—É. '
                    f'2) –ü—Ä–æ–π–¥–∏: –Ω–∞–∑–≤–∞–Ω–∏–µ ‚Üí –û–ì–†–ù ‚Üí –∞–¥—Ä–µ—Å ‚Üí –û–†–ù–ó. '
                    f'3) –ò–∑–≤–ª–µ–∫–∏ 11-–∑–Ω–∞—á–Ω—ã–π –Ω–æ–º–µ—Ä –ø–æ—Å–ª–µ ¬´–û–†–ù–ó:¬ª"'
                )
            else:
                # Text field - direct extraction
                if fid == "field_17":
                    # Special handling for —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∑–∞–¥–∞–Ω–∏—è –ø–æ –∞—É–¥–∏—Ç—É
                    fields_list.append(
                        f"**{fid} ({fname})**\n"
                        f"  - –û–ø–∏—Å–∞–Ω–∏–µ: {field_desc}\n"
                        f"  - –¢–∏–ø: —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –ø–æ–ª–µ\n"
                        f"  - –î–µ–π—Å—Ç–≤–∏–µ: –∏–∑–≤–ª–µ–∫–∏ –∑–Ω–∞—á–µ–Ω–∏–µ, —Å–ª–µ–¥—É—è –°–¢–†–û–ì–û–ô –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏\n\n"
                        f"  üîç –ú–ï–¢–û–î–û–õ–û–ì–ò–Ø –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –í –¢–ê–ö–û–ú –ü–û–†–Ø–î–ö–ï!):\n\n"
                        f"  –®–ê–ì 1 ‚Äî –ü–†–ò–û–†–ò–¢–ï–¢ 1: –ü–æ–∏—Å–∫ —è–≤–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —É–∫–∞–∑–∞–Ω–∏—è:\n"
                        f"    ‚Ä¢ –ü—Ä–æ—Å–º–æ—Ç—Ä–∏ –í–°–ï –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã\n"
                        f"    ‚Ä¢ –ò—â–∏ —Ñ—Ä–∞–∑—ã: ¬´–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∞—É–¥–∏—Ç–∞¬ª, ¬´–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∑–∞–¥–∞–Ω–∏—è –ø–æ –∞—É–¥–∏—Ç—É¬ª, "
                        f"¬´–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∑–∞–¥–∞–Ω–∏—è¬ª, ¬´—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∞—É–¥–∏—Ç–∞, –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –∫–æ—Ç–æ—Ä–æ–≥–æ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–æ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ¬ª\n"
                        f"    ‚Ä¢ –ü—Ä–æ–≤–µ—Ä—è–π –ò –≤ —Ç–µ–∫—Å—Ç–µ –∑–∞–∫–ª—é—á–µ–Ω–∏—è, –ò –≤ –±–ª–æ–∫–µ –ø–æ–¥–ø–∏—Å–µ–π\n"
                        f"    ‚Ä¢ –ï–°–õ–ò –ù–ê–ô–î–ï–ù–û ‚Üí —ç—Ç–æ field_17, –ø–µ—Ä–µ—Ö–æ–¥–∏ –∫ –∏–∑–≤–ª–µ—á–µ–Ω–∏—é –§–ò–û\n\n"
                        f"  –®–ê–ì 2 ‚Äî –ü–†–ò–û–†–ò–¢–ï–¢ 2: –ü–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ–µ –ø—Ä–∞–≤–∏–ª–æ (–¢–û–õ–¨–ö–û –µ—Å–ª–∏ –Ω–µ—Ç —è–≤–Ω—ã—Ö —É–∫–∞–∑–∞–Ω–∏–π!):\n"
                        f"    ‚Ä¢ –ï–°–õ–ò –≤ –®–∞–≥–µ 1 –ù–ï –Ω–∞–π–¥–µ–Ω–æ —è–≤–Ω—ã—Ö —É–∫–∞–∑–∞–Ω–∏–π\n"
                        f"    ‚Ä¢ –¢–û–ì–î–ê —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∑–∞–¥–∞–Ω–∏—è = –ø–µ—Ä–≤—ã–π –ø–æ–¥–ø–∏—Å–∞–Ω—Ç –≤ –±–ª–æ–∫–µ –ø–æ–¥–ø–∏—Å–µ–π\n\n"
                        f"  ‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ù–û: ¬´–î–∏—Ä–µ–∫—Ç–æ—Ä –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏¬ª / ¬´–ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä¬ª ‚â† ¬´–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∑–∞–¥–∞–Ω–∏—è –ø–æ –∞—É–¥–∏—Ç—É¬ª!\n"
                        f"    ‚Ä¢ –î–∏—Ä–µ–∫—Ç–æ—Ä –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ ‚Äî —ç—Ç–æ –¥–æ–ª–∂–Ω–æ—Å—Ç—å –≤ –∞—É–¥–∏—Ç–æ—Ä—Å–∫–æ–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏\n"
                        f"    ‚Ä¢ –†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∑–∞–¥–∞–Ω–∏—è ‚Äî —ç—Ç–æ —Ä–æ–ª—å –≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º –∞—É–¥–∏—Ç–µ\n"
                        f"    ‚Ä¢ –û–¥–Ω–æ –ª–∏—Ü–æ –º–æ–∂–µ—Ç —Å–æ–≤–º–µ—â–∞—Ç—å –æ–±–µ —Ä–æ–ª–∏, –Ω–æ –ù–ï –≤—Å–µ–≥–¥–∞!\n"
                        f"    ‚Ä¢ –ü—Ä–∏–º–µ—Ä:\n"
                        f"      –ü–æ–¥–ø–∏—Å—å 1: –ò–≤–∞–Ω–æ–≤ –ò.–ò. ‚Äî –ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä –ê–û ¬´–ê—É–¥–∏—Ç¬ª\n"
                        f"      –ü–æ–¥–ø–∏—Å—å 2: –ü–µ—Ç—Ä–æ–≤ –ü.–ü. ‚Äî –†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∞—É–¥–∏—Ç–∞\n"
                        f"      ‚Üí field_17 = –ü–µ—Ç—Ä–æ–≤ –ü.–ü. (–¥–∞–∂–µ –µ—Å–ª–∏ –≤—Ç–æ—Ä–æ–π –ø–æ –ø–æ—Ä—è–¥–∫—É)\n\n"
                        f"  üìã –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –§–ò–û:\n"
                        f"    ‚Ä¢ –ü–æ—Å–ª–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ª–∏—Ü–∞ –∏–∑–≤–ª–µ–∫–∏ –ø–æ–ª–Ω–æ–µ –§–ò–û\n"
                        f"    ‚Ä¢ –§–æ—Ä–º–∞—Ç: ¬´–§–∞–º–∏–ª–∏—è –ò.–û.¬ª –∏–ª–∏ –ø–æ–ª–Ω–æ–µ –∏–º—è –æ—Ç—á–µ—Å—Ç–≤–æ, –∫–∞–∫ —É–∫–∞–∑–∞–Ω–æ\n"
                        f"    ‚Ä¢ –í–∫–ª—é—á–∏ –≤ reasoning: –Ω–∞ –∫–∞–∫–æ–º –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω (—è–≤–Ω–æ–µ —É–∫–∞–∑–∞–Ω–∏–µ –∏–ª–∏ –ø–æ–∑–∏—Ü–∏—è)"
                    )
                else:
                    # Regular text field
                    fields_list.append(
                        f"**{fid} ({fname})**\n"
                        f"  - –û–ø–∏—Å–∞–Ω–∏–µ: {field_desc}\n"
                        f"  - –¢–∏–ø: —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –ø–æ–ª–µ\n"
                        f"  - –î–µ–π—Å—Ç–≤–∏–µ: –∏–∑–≤–ª–µ–∫–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–∞–ø—Ä—è–º—É—é –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"
                    )

        fields_text = "\n\n".join(fields_list)

        blocks_section = f"\n\n**–ù–∞–π–¥–µ–Ω–Ω—ã–µ –±–ª–æ–∫–∏:**\n{blocks_info}\n" if blocks_info else ""

        special_notes = f"\n\n**–û—Å–æ–±—ã–µ –∑–∞–º–µ—á–∞–Ω–∏—è:**\n{group.get('special_notes', '')}\n" if group.get('special_notes') else ""

        # Add consistency checking for auditors group
        consistency_check = ""
        if group.get('name') == 'auditors':
            consistency_check = (
                f"**–ü–†–û–í–ï–†–ö–ê –°–û–ì–õ–ê–°–û–í–ê–ù–ù–û–°–¢–ò (–ø–µ—Ä–µ–¥ —Ñ–∏–Ω–∞–ª—å–Ω—ã–º –æ—Ç–≤–µ—Ç–æ–º!):**\n\n"
                f"‚ö†Ô∏è –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–ê–Ø –í–ê–õ–ò–î–ê–¶–ò–Ø –¥–ª—è field_17 –∏ field_20:\n\n"
                f"1. field_17 (–§–ò–û —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è –∑–∞–¥–∞–Ω–∏—è) vs field_20 (–§–ò–û –≤—Ç–æ—Ä–æ–≥–æ –ª–∏—Ü–∞):\n"
                f"   ‚Ä¢ –≠—Ç–æ –†–ê–ó–ù–´–ï –ª—é–¥–∏!\n"
                f"   ‚Ä¢ field_17 –ù–ï –ú–û–ñ–ï–¢ –±—ã—Ç—å —Ä–∞–≤–µ–Ω field_20\n"
                f"   ‚Ä¢ –ï—Å–ª–∏ –æ–Ω–∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç ‚Üí –æ—à–∏–±–∫–∞ –≤ –ª–æ–≥–∏–∫–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è\n\n"
                f"2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–∏–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è field_17:\n"
                f"   ‚Ä¢ –ï–°–õ–ò –≤ reasoning –¥–ª—è field_17 –Ω–∞–ø–∏—Å–∞–Ω–æ ¬´–ø–µ—Ä–≤—ã–π –ø–æ–¥–ø–∏—Å–∞–Ω—Ç¬ª\n"
                f"     –ò –µ—Å—Ç—å —è–≤–Ω–æ–µ —É–∫–∞–∑–∞–Ω–∏–µ ¬´–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∞—É–¥–∏—Ç–∞¬ª —É –¥—Ä—É–≥–æ–≥–æ –ª–∏—Ü–∞\n"
                f"     ‚Üí –û–®–ò–ë–ö–ê! –¢—ã –ø—Ä–æ–ø—É—Å—Ç–∏–ª —è–≤–Ω–æ–µ —É–∫–∞–∑–∞–Ω–∏–µ (–ü–†–ò–û–†–ò–¢–ï–¢ 1)\n"
                f"   ‚Ä¢ –ï–°–õ–ò –≤ reasoning –Ω–∞–ø–∏—Å–∞–Ω–æ ¬´–î–∏—Ä–µ–∫—Ç–æ—Ä –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏¬ª –ë–ï–ó —É–ø–æ–º–∏–Ω–∞–Ω–∏—è ¬´–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∞—É–¥–∏—Ç–∞¬ª\n"
                f"     ‚Üí –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï! –ü—Ä–æ–≤–µ—Ä—å –≤–µ—Å—å –¥–æ–∫—É–º–µ–Ω—Ç –Ω–∞ —è–≤–Ω—ã–µ —É–∫–∞–∑–∞–Ω–∏—è\n\n"
                f"3. –ï—Å–ª–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –Ω–µ—Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å:\n"
                f"   ‚Ä¢ –ü–ï–†–ï–°–ú–û–¢–†–ò –≤—Å—é –¥–æ—Å—Ç—É–ø–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é\n"
                f"   ‚Ä¢ –°–ª–µ–¥—É–π –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏ –¥–ª—è field_17 –∑–∞–Ω–æ–≤–æ\n"
                f"   ‚Ä¢ –£–±–µ–¥–∏—Å—å, —á—Ç–æ –ø—Ä–∏–º–µ–Ω–∏–ª –ü–†–ò–û–†–ò–¢–ï–¢ 1 (—è–≤–Ω—ã–µ —É–∫–∞–∑–∞–Ω–∏—è) –ø–µ—Ä–µ–¥ –ü–†–ò–û–†–ò–¢–ï–¢ 2 (–ø–æ–∑–∏—Ü–∏—è)\n\n"
            )

        return (
            f"# –§–ê–ó–ê 2: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–ª–µ–π\n\n"
            f"## –ì—Ä—É–ø–ø–∞ –¥–∞–Ω–Ω—ã—Ö: {group['display_name']}\n\n"
            f"{blocks_section}"
            f"**–î–æ—Å—Ç—É–ø–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã:** {page_nums or '–Ω–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü'}\n\n"
            f"**–ü–æ–ª—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è:**\n\n{fields_text}\n"
            f"{special_notes}\n"
            f"**–°–¢–†–ê–¢–ï–ì–ò–Ø –ü–†–ò no_data –û–¢ ask_qwen:**\n"
            f"- –ü—Ä–∏ –ü–û–í–¢–û–†–ù–û–ú –≤—ã–∑–æ–≤–µ –¥–ª—è –¢–û–ì–û –ñ–ï field_id ‚Äî –∏–∑–º–µ–Ω–∏ page_num –Ω–∞ –¥—Ä—É–≥—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É\n"
            f"- –ù–ï –≤—ã–∑—ã–≤–∞–π —Å —Ç–µ–º –∂–µ page_num ‚Äî —ç—Ç–æ –±–µ—Å–ø–æ–ª–µ–∑–Ω–æ!\n"
            f"- –î–ª—è –ù–û–í–û–ì–û field_id –º–æ–∂–µ—à—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª—é–±—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É\n"
            f"- –ï—Å–ª–∏ –ø–µ—Ä–µ–±—Ä–∞–ª –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–∞–Ω–∏—Ü –∏ –≤–µ–∑–¥–µ no_data ‚Äî –≤–µ—Ä–Ω–∏ no_data\n\n"
            f"{consistency_check}"
            f"**–§–û–†–ú–ê–¢ –§–ò–ù–ê–õ–¨–ù–û–ì–û –û–¢–í–ï–¢–ê (JSON):**\n"
            "{\n"
            '  "field_03": {\n'
            '    "value": <–∑–Ω–∞—á–µ–Ω–∏–µ>,\n'
            '    "status": "ok" | "no_data" | "error",\n'
            '    "reasoning": ["–æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ"],\n'
            '    "meta": {"page": <–Ω–æ–º–µ—Ä>}  // –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ\n'
            "  },\n"
            "  // ... –¥–ª—è –≤—Å–µ—Ö –ø–æ–ª–µ–π –≥—Ä—É–ø–ø—ã\n"
            "}\n\n"
            "–í–ê–ñ–ù–û: –í–µ—Ä–Ω–∏ JSON –¢–û–õ–¨–ö–û –ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ç –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö tools!"
        )

    def _parse_group_response(
        self,
        group: Dict,
        response_text: Optional[str],
        existing_results: Optional[Dict[str, FieldResult]] = None
    ) -> Dict[str, FieldResult]:
        """
        Parse batch response with STRICT validation - no softening!
        Merges with existing_results from tools (tools have priority).
        """
        # Start with results from tools (if any)
        results: Dict[str, FieldResult] = dict(existing_results) if existing_results else {}

        group_name = group["name"]
        field_ids = group["fields"]

        if not response_text:
            # No text response - return error for fields not already in results
            for field_id in field_ids:
                if field_id not in results:
                    results[field_id] = FieldResult(
                        field_id=field_id,
                        name=self._field_name(field_id),
                        status=FIELD_STATUS_ERROR,
                        value=None,
                        reasoning=["no_text_response_from_model"],
                    )
            return results

        # Clean markdown fence from response (Gemini returns JSON wrapped in ```json ... ```)
        response_text = response_text.strip()
        if response_text.startswith("```"):
            # Remove ```json or ``` at start
            lines = response_text.split('\n')
            if lines[0].startswith("```"):
                lines = lines[1:]  # Remove first line with ```json
            if lines and lines[-1].strip() == "```":
                lines = lines[:-1]  # Remove last line with ```
            response_text = '\n'.join(lines).strip()
            self._log(f"group={group_name} cleaned_markdown_fence from_response")

        try:
            payload = json.loads(response_text)
        except json.JSONDecodeError as e:
            self._log(f"json_decode_error group={group_name} err={e}")
            self._log(f"group={group_name} problematic_text: {response_text[:500]}")
            for field_id in field_ids:
                if field_id not in results:
                    results[field_id] = FieldResult(
                        field_id=field_id,
                        name=self._field_name(field_id),
                        status=FIELD_STATUS_ERROR,
                        value=None,
                        reasoning=[f"json_decode_error: {e}"],
                    )
            return results

        if not isinstance(payload, dict):
            self._log(f"response_not_dict group={group_name}")
            for field_id in field_ids:
                if field_id not in results:
                    results[field_id] = FieldResult(
                        field_id=field_id,
                        name=self._field_name(field_id),
                        status=FIELD_STATUS_ERROR,
                        value=None,
                        reasoning=["response_not_dict"],
                    )
            return results

        allowed_statuses = {FIELD_STATUS_OK, FIELD_STATUS_NO_DATA, FIELD_STATUS_ERROR, FIELD_STATUS_SKIPPED}

        for field_id in field_ids:
            # Skip fields already populated by tools (tools have priority)
            if field_id in results:
                self._log(f"group={group_name} field={field_id} already_in_results_from_tool, skipping_gemini_parse")
                continue

            name = self._field_name(field_id)
            raw_entry = payload.get(field_id)

            if raw_entry is None:
                results[field_id] = FieldResult(
                    field_id=field_id,
                    name=name,
                    status=FIELD_STATUS_ERROR,
                    value=None,
                    reasoning=["field_missing_in_response"],
                )
                continue

            if not isinstance(raw_entry, dict):
                results[field_id] = FieldResult(
                    field_id=field_id,
                    name=name,
                    status=FIELD_STATUS_ERROR,
                    value=None,
                    reasoning=["field_value_not_dict"],
                )
                continue

            status = raw_entry.get("status")
            value = raw_entry.get("value")
            reasoning = raw_entry.get("reasoning") or []
            meta = raw_entry.get("meta") if isinstance(raw_entry.get("meta"), dict) else None

            if isinstance(reasoning, str):
                reasoning = [reasoning]

            # STRICT validation - no status coercion!
            if status not in allowed_statuses:
                results[field_id] = FieldResult(
                    field_id=field_id,
                    name=name,
                    status=FIELD_STATUS_ERROR,
                    value=None,
                    reasoning=[f"invalid_status_from_model: {status}"] + (list(reasoning) if reasoning else []),
                    meta=meta,
                )
                continue

            results[field_id] = FieldResult(
                field_id=field_id,
                name=name,
                status=status,
                value=value,
                reasoning=list(reasoning),
                notes=[],
                meta=meta,
            )

        # Special handling for auditors group: duplicate field_17-19 ‚Üí field_20-22 if second person is missing
        if group_name == "auditors":
            field_20 = results.get("field_20")
            field_17 = results.get("field_17")
            field_18 = results.get("field_18")
            field_19 = results.get("field_19")

            # If field_20 is no_data and field_17 exists with ok status, duplicate data
            if (field_20 and field_20.status == FIELD_STATUS_NO_DATA and
                field_17 and field_17.status == FIELD_STATUS_OK):

                # Duplicate field_17 ‚Üí field_20
                results["field_20"] = FieldResult(
                    field_id="field_20",
                    name=self._field_name("field_20"),
                    status=field_17.status,
                    value=field_17.value,
                    reasoning=list(field_17.reasoning) + ["–í—Ç–æ—Ä–æ–µ –ª–∏—Ü–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç - –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ–¥—É–±–ª–∏—Ä–æ–≤–∞–Ω—ã –∏–∑ field_17"],
                    notes=list(field_17.notes),
                    meta=copy.deepcopy(field_17.meta) if field_17.meta else None
                )

                # Duplicate field_18 ‚Üí field_21
                if field_18 and field_18.status == FIELD_STATUS_OK:
                    results["field_21"] = FieldResult(
                        field_id="field_21",
                        name=self._field_name("field_21"),
                        status=field_18.status,
                        value=field_18.value,
                        reasoning=list(field_18.reasoning) + ["–í—Ç–æ—Ä–æ–µ –ª–∏—Ü–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç - –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ–¥—É–±–ª–∏—Ä–æ–≤–∞–Ω—ã –∏–∑ field_18"],
                        notes=list(field_18.notes),
                        meta=copy.deepcopy(field_18.meta) if field_18.meta else None
                    )

                # Duplicate field_19 ‚Üí field_22
                if field_19 and field_19.status == FIELD_STATUS_OK:
                    results["field_22"] = FieldResult(
                        field_id="field_22",
                        name=self._field_name("field_22"),
                        status=field_19.status,
                        value=field_19.value,
                        reasoning=list(field_19.reasoning) + ["–í—Ç–æ—Ä–æ–µ –ª–∏—Ü–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç - –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ–¥—É–±–ª–∏—Ä–æ–≤–∞–Ω—ã –∏–∑ field_19"],
                        notes=list(field_19.notes),
                        meta=copy.deepcopy(field_19.meta) if field_19.meta else None
                    )

                self._log(f"group=auditors duplicated field_17-19 to field_20-22 (second person absent)")

        return results

    def _execute_function_call(
        self,
        func_name: str,
        func_args: Dict,
        context: ProcessingContext,
        results: Dict[str, FieldResult],
        available_pages: Optional[List[int]] = None
    ) -> Dict:
        """
        Execute function call and return result.
        For ask_qwen: writes result directly to results dict, returns only status message.
        For registry lookups: writes result to results dict, returns only status message.
        """
        self._log(f"execute_function_call name={func_name} args={func_args}")

        if func_name == "ask_qwen":
            field_id = func_args.get("field_id")
            page_num = func_args.get("page_num")
            question_text = func_args.get("question_text")

            if not all([field_id, page_num is not None, question_text]):
                return {
                    "status": "error",
                    "message": "missing_required_args"
                }

            page_img = self._render_single_page(context, page_num)
            tool_res = ask_qwen(
                field_id=field_id,
                field_name=self._field_name(field_id),
                page_num=page_num,
                question_text=question_text,
                page_image=page_img,
                qwen_client=self.qwen_client,
                run_logger=self.run_logger,
                log_dir=self.log_dir,
            )

            # Write result directly to results dict (convert ToolCallResult -> FieldResult)
            results[field_id] = tool_result_to_field_result(field_id, self._field_name(field_id), tool_res)
            self._log(f"ask_qwen result written to results[{field_id}]: status={tool_res.status}, value={tool_res.value}")

            # Return status message to Gemini with context and explanation for validation
            if tool_res.status == FIELD_STATUS_OK:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º context –∏ explanation –∏–∑ reasoning –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ Gemini
                context_parts = [r for r in tool_res.reasoning if r.startswith("context=")]
                explanation_parts = [r for r in tool_res.reasoning if r.startswith("explanation=")]
                qwen_context = context_parts[0].replace("context=", "") if context_parts else ""
                qwen_explanation = explanation_parts[0].replace("explanation=", "") if explanation_parts else ""

                return {
                    "status": "success",
                    "qwen_context": qwen_context,
                    "qwen_explanation": qwen_explanation,
                    "message": (
                        f"Qwen –∏–∑–≤–ª—ë–∫ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è {field_id} —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}.\n\n"
                        f"–ò–ó–í–õ–ï–ß–Å–ù–ù–û–ï: {tool_res.value}\n"
                        f"–ö–û–ù–¢–ï–ö–°–¢ (–≥–¥–µ –Ω–∞—à—ë–ª): {qwen_context or '–Ω–µ —É–∫–∞–∑–∞–Ω'}\n"
                        f"–ü–û–Ø–°–ù–ï–ù–ò–ï: {qwen_explanation or '–Ω–µ —É–∫–∞–∑–∞–Ω–æ'}\n\n"
                        f"‚ö†Ô∏è –í–ê–ñ–ù–û: –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ò–ó–í–õ–ï–ß–Å–ù–ù–û–ï, –ö–û–ù–¢–ï–ö–°–¢ –∏ –ü–û–Ø–°–ù–ï–ù–ò–ï!\n"
                        f"- –£–±–µ–¥–∏—Å—å, —á—Ç–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –ù–£–ñ–ù–û–ì–û –æ–±—ä–µ–∫—Ç–∞\n"
                        f"- –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –î–†–£–ì–û–ô –æ–±—ä–µ–∫—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ñ–∏–∑–ª–∏—Ü–æ –≤–º–µ—Å—Ç–æ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏) "
                        f"‚Üí –ü–û–í–¢–û–†–ò ask_qwen —Å –£–¢–û–ß–ù–Å–ù–ù–û–ô –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π\n"
                        f"- –ï—Å–ª–∏ –≤—Å—ë –ø—Ä–∞–≤–∏–ª—å–Ω–æ ‚Üí –ø–µ—Ä–µ—Ö–æ–¥–∏ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –ø–æ–ª—é\n\n"
                        f"‚ö†Ô∏è –ü—Ä–æ–≤–µ—Ä—å —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å: —Å–æ–≤–ø–∞–¥–∞–µ—Ç –ª–∏ –ò–ó–í–õ–ï–ß–Å–ù–ù–û–ï —Å —Ç–µ–º, —á—Ç–æ –¥–∞–Ω–æ –≤ –ö–û–ù–¢–ï–ö–°–¢–ï?\n"
                        f"   ‚Üí –ï—Å–ª–∏ –ù–ï–¢: –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–µ! –ü–û–í–¢–û–†–ò ask_qwen —Å –£–¢–û–ß–ù–Å–ù–ù–û–ô –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π\n\n"
                        f"–£–¢–û–ß–ù–Å–ù–ù–´–ï –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –º–æ–≥—É—Ç –≤—ã—Ä–∞–∂–∞—Ç—å—Å—è –≤ —Å–ª–µ–¥—É—é—â–µ–º:\n"
                        f"- —É—Ç–æ—á–Ω–µ–Ω–∏–µ, –ì–î–ï –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –Ω—É–∂–Ω—ã–π –æ–±—ä–µ–∫—Ç, –¥–µ—Ç–∞–ª–∏ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏—è\n"
                        f"- —É—Ç–æ—á–Ω–µ–Ω–∏–µ, –ö–ê–ö –æ—Ç–ª–∏—á–∏—Ç—å –æ—Ç –¥—Ä—É–≥–∏—Ö\n"
                        f"- —É–∫–∞–∑–∞–Ω–∏–µ –¥—Ä—É–≥–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã\n"
                        f"- –ø—Ä–æ—Å—å–±–∞ —Å—Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞—Ç—å—Å—è.\n"
                        f"–ü—Ä–∏ —ç—Ç–æ–º –Ω—É–∂–Ω–æ –ø–æ–º–Ω–∏—Ç—å, —á—Ç–æ ask_qwen –Ω–µ –ø–æ–º–Ω–∏—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ ‚Äî "
                        f"–∫–∞–∂–¥—ã–π –Ω–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –≤–æ—Å–ø—Ä–∏–Ω–∏–º–∞–µ—Ç—Å—è –∏–º –∫–∞–∫ –Ω–æ–≤—ã–π, "
                        f"–ø–æ—ç—Ç–æ–º—É —É—Ç–æ—á–Ω—ë–Ω–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ü–û–õ–ù–û–ô –∏ –°–ê–ú–û–î–û–°–¢–ê–¢–û–ß–ù–û–ô."
                    )
                }
            elif tool_res.status == FIELD_STATUS_NO_DATA:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º explanation –∏–∑ reasoning (–µ—Å–ª–∏ –µ—Å—Ç—å)
                explanation_parts = [r for r in tool_res.reasoning if r.startswith("explanation=")]
                qwen_explanation = explanation_parts[0].replace("explanation=", "") if explanation_parts else ""
                
                other_pages = [p for p in (available_pages or []) if p != page_num]
                pages_hint = f" –î–æ—Å—Ç—É–ø–Ω—ã–µ: {other_pages}" if other_pages else ""
                return {
                    "status": "no_data",
                    "qwen_said": qwen_explanation,
                    "message": (
                        f"–ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_num} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è {field_id}.\n"
                        f"Qwen –ø–æ—è—Å–Ω–∏–ª: {qwen_explanation or '–±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π'}\n\n"
                        f"–í–∞—Ä–∏–∞–Ω—Ç—ã –¥–µ–π—Å—Ç–≤–∏–π:\n"
                        f"1. –£—Ç–æ—á–Ω–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –∏ –ø–æ–≤—Ç–æ—Ä–∏ ask_qwen –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}\n"
                        f"2. –ü–æ–ø—Ä–æ–±—É–π –î–†–£–ì–£–Æ —Å—Ç—Ä–∞–Ω–∏—Ü—É.{pages_hint}"
                    )
                }
            else:
                return {
                    "status": "error",
                    "message": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ {field_id}: {', '.join(tool_res.reasoning)}"
                }

        # Unknown function
        return {
            "status": "error",
            "message": f"unknown_function: {func_name}"
        }

    def _process_group_with_phases(
        self,
        group: Dict,
        images_union: List[bytes],
        page_nums: List[int],
        context: ProcessingContext,
        system_prompt: Optional[str] = None,
        max_iterations: int = 10
    ) -> Dict[str, FieldResult]:
        """
        Process group with optional two-phase approach:
        - Phase 1 (if block_discovery=True): Block Discovery
        - Phase 2: Field Extraction with agentic loop

        Tool results are written directly to results dict (not passed through Gemini).
        """
        # Results dict - tools write directly here
        results: Dict[str, FieldResult] = {}

        group_name = group["name"]
        blocks_info = None

        # PHASE 1: Block Discovery (if required)
        if group.get("block_discovery"):
            self._log(f"group={group_name} starting_phase_1_block_discovery")

            block_prompt = self._build_block_discovery_prompt(group, page_nums)

            # Build user message for Phase 1
            if system_prompt:
                # First group: system prompt + block discovery prompt + images
                user_text = f"{system_prompt}\n\n{block_prompt}"
                user_parts = [{"text": user_text}]
                for img_bytes in images_union:
                    b64_data = base64.b64encode(img_bytes).decode('utf-8')
                    user_parts.append({
                        "inline_data": {
                            "mime_type": "image/jpeg",
                            "data": b64_data
                        }
                    })
            else:
                # Subsequent groups: only text (images already in history)
                user_parts = [{"text": block_prompt}]

            self.messages.append({
                "role": "user",
                "parts": user_parts
            })

            # Call Gemini for Block Discovery (no tools expected here)
            try:
                response = self.client.generate_content_with_tools(
                    messages=self.messages,
                    tools=self.tools
                )
                blocks_response = response.get("text", "")

                if blocks_response:
                    self._log(f"group={group_name} phase_1_response_len={len(blocks_response)}")
                    self._log(f"group={group_name} phase_1_response={blocks_response}")
                    blocks_info = blocks_response

                    # Add model's response to messages
                    self.messages.append({
                        "role": "model",
                        "parts": [{"text": blocks_response}]
                    })
                else:
                    self._log(f"group={group_name} phase_1_no_response")
                    blocks_info = "–ë–ª–æ–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"

            except Exception as e:  # noqa: BLE001
                self._log(f"group={group_name} phase_1_failed err={e}")
                blocks_info = f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –±–ª–æ–∫–æ–≤: {e}"

        # PHASE 2: Field Extraction with agentic loop
        self._log(f"group={group_name} starting_phase_2_field_extraction")

        field_prompt = self._build_field_extraction_prompt(group, page_nums, blocks_info)

        # Build user message for Phase 2
        # Note: images are already in history from Phase 1, or we add them here for first group without block_discovery
        if system_prompt and not group.get("block_discovery"):
            # First group without block discovery: add system prompt + field extraction + images
            user_text = f"{system_prompt}\n\n{field_prompt}"
            user_parts = [{"text": user_text}]
            for img_bytes in images_union:
                b64_data = base64.b64encode(img_bytes).decode('utf-8')
                user_parts.append({
                    "inline_data": {
                        "mime_type": "image/jpeg",
                        "data": b64_data
                    }
                })
        else:
            # Phase 2 after Phase 1, or subsequent groups: just text
            user_parts = [{"text": field_prompt}]

        self.messages.append({
            "role": "user",
            "parts": user_parts
        })

        # Agentic loop for Field Extraction
        for iteration in range(max_iterations):
            self._log(f"group={group_name} phase_2_iteration={iteration+1}/{max_iterations}")
            self._log(f"group={group_name} sending messages_count={len(self.messages)}")

            try:
                response = self.client.generate_content_with_tools(
                    messages=self.messages,
                    tools=self.tools
                )
            except Exception as e:  # noqa: BLE001
                self._log(f"gemini_call_failed group={group_name} iteration={iteration+1} err={e}")
                return {
                    field_id: FieldResult(
                        field_id=field_id,
                        name=self._field_name(field_id),
                        status=FIELD_STATUS_ERROR,
                        value=None,
                        reasoning=[f"gemini_call_failed: {e}"],
                    )
                    for field_id in group["fields"]
                }

            function_calls = response.get("function_calls")
            text_response = response.get("text")

            self._log(f"group={group_name} iteration={iteration+1} response: function_calls={len(function_calls) if function_calls else 0}, text_len={len(text_response) if text_response else 0}")
            if text_response:
                self._log(f"group={group_name} iteration={iteration+1} text_preview: {text_response[:500]}")

            if function_calls:
                # Model wants to call functions
                self._log(f"group={group_name} function_calls={len(function_calls)}")

                # Add model's function call to messages
                model_parts = []
                for fc in function_calls:
                    model_parts.append({
                        "functionCall": {
                            "name": fc["name"],
                            "args": fc["args"]
                        }
                    })

                self.messages.append({
                    "role": "model",
                    "parts": model_parts
                })

                # Execute all function calls and collect responses
                function_responses = []
                for fc in function_calls:
                    result = self._execute_function_call(fc["name"], fc["args"], context, results, page_nums)
                    self._log(f"group={group_name} function_result: {fc['name']} -> {json.dumps(result, ensure_ascii=False)}")
                    function_responses.append({
                        "functionResponse": {
                            "name": fc["name"],
                            "response": result
                        }
                    })

                # Add function responses to messages
                self.messages.append({
                    "role": "user",
                    "parts": function_responses
                })
                self._log(f"group={group_name} added function_responses to messages, total_messages={len(self.messages)}")

                # Continue loop - model will process function results

            elif text_response:
                # Model returned text response (final answer)
                self._log(f"group={group_name} got_text_response")

                # Add model's text response to messages
                self.messages.append({
                    "role": "model",
                    "parts": [{"text": text_response}]
                })

                # Parse and merge with tool results
                return self._parse_group_response(group, text_response, results)

            else:
                # No function calls and no text - error
                self._log(f"group={group_name} no_function_calls_and_no_text")
                return {
                    field_id: FieldResult(
                        field_id=field_id,
                        name=self._field_name(field_id),
                        status=FIELD_STATUS_ERROR,
                        value=None,
                        reasoning=["no_function_calls_and_no_text_from_model"],
                    )
                    for field_id in group["fields"]
                }

        # Max iterations reached
        self._log(f"group={group_name} max_iterations_reached")
        return {
            field_id: FieldResult(
                field_id=field_id,
                name=self._field_name(field_id),
                status=FIELD_STATUS_ERROR,
                value=None,
                reasoning=["max_iterations_reached_in_agentic_loop"],
            )
            for field_id in group["fields"]
        }

    def run(self, document, triage, context: ProcessingContext) -> List[FieldResult]:
        """
        Run hybrid dialogue extraction using EXTRACTION_GROUPS.
        Two-phase approach for groups with block_discovery=True.
        """
        self.messages.clear()
        self.pages_cache.clear()

        # Missing files -> fast path
        if getattr(document, "missing_reason", None):
            return [
                FieldResult(
                    field_id=f"field_{idx:02d}",
                    name=ALL_HEADERS[idx],
                    status=FIELD_STATUS_SKIPPED,
                    value=None,
                    reasoning=[getattr(document, "missing_reason")],
                )
                for idx in range(len(ALL_HEADERS))
            ]

        # Initialize golden source cache with marked pages
        self._initialize_pages_cache(context)
        
        extraction: Dict[str, FieldResult] = {}
        images_union, page_nums = self._render_union_pages(context)

        system_prompt = self._build_system_prompt()
        first_group = True

        # Process each extraction group
        for group in EXTRACTION_GROUPS:
            self._log(f"processing_group name={group['name']} fields={group['fields']}")

            group_results = self._process_group_with_phases(
                group,
                images_union,
                page_nums,
                context,
                system_prompt=system_prompt if first_group else None
            )
            extraction.update(group_results)
            first_group = False

        # Field 00 (row number) and always_skipped 30
        extraction.setdefault(
            "field_00",
            FieldResult(field_id="field_00", name=ALL_HEADERS[0], status=FIELD_STATUS_SKIPPED, reasoning=["not_applicable"]),
        )
        extraction.setdefault(
            "field_30",
            FieldResult(field_id="field_30", name=ALL_HEADERS[30], status=FIELD_STATUS_SKIPPED, reasoning=["always_skipped"]),
        )

        # Fill missing with no_data (for fields not in any group)
        for idx, name in enumerate(ALL_HEADERS):
            fid = f"field_{idx:02d}"
            if fid not in extraction:
                extraction[fid] = FieldResult(
                    field_id=fid,
                    name=name,
                    status=FIELD_STATUS_NO_DATA,
                    value=None,
                    reasoning=["not_in_extraction_groups"],
                )

        # Return ordered list
        ordered: List[FieldResult] = []
        for idx in range(len(ALL_HEADERS)):
            fid = f"field_{idx:02d}"
            ordered.append(extraction.get(fid))
        return ordered
